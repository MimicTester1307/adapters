{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.012277470841006752,
  "eval_steps": 500,
  "global_step": 100,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00012277470841006753,
      "grad_norm": 0.08713089674711227,
      "learning_rate": 1e-05,
      "loss": 1.9294,
      "step": 1
    },
    {
      "epoch": 0.00024554941682013506,
      "grad_norm": 0.11003869026899338,
      "learning_rate": 2e-05,
      "loss": 2.0282,
      "step": 2
    },
    {
      "epoch": 0.00036832412523020257,
      "grad_norm": 0.10351220518350601,
      "learning_rate": 3e-05,
      "loss": 2.2305,
      "step": 3
    },
    {
      "epoch": 0.0004910988336402701,
      "grad_norm": 0.10804050415754318,
      "learning_rate": 4e-05,
      "loss": 2.1984,
      "step": 4
    },
    {
      "epoch": 0.0006138735420503376,
      "grad_norm": 0.13016773760318756,
      "learning_rate": 5e-05,
      "loss": 1.9873,
      "step": 5
    },
    {
      "epoch": 0.0007366482504604051,
      "grad_norm": 0.1201828345656395,
      "learning_rate": 6e-05,
      "loss": 2.1256,
      "step": 6
    },
    {
      "epoch": 0.0008594229588704727,
      "grad_norm": 0.1405089795589447,
      "learning_rate": 7.000000000000001e-05,
      "loss": 2.2166,
      "step": 7
    },
    {
      "epoch": 0.0009821976672805403,
      "grad_norm": 0.14758263528347015,
      "learning_rate": 8e-05,
      "loss": 2.1917,
      "step": 8
    },
    {
      "epoch": 0.0011049723756906078,
      "grad_norm": 0.1540498584508896,
      "learning_rate": 8.999999999999999e-05,
      "loss": 2.1484,
      "step": 9
    },
    {
      "epoch": 0.0012277470841006752,
      "grad_norm": 0.18329884111881256,
      "learning_rate": 0.0001,
      "loss": 2.1777,
      "step": 10
    },
    {
      "epoch": 0.0013505217925107427,
      "grad_norm": 0.21841728687286377,
      "learning_rate": 0.00011,
      "loss": 2.1748,
      "step": 11
    },
    {
      "epoch": 0.0014732965009208103,
      "grad_norm": 0.22790993750095367,
      "learning_rate": 0.00012,
      "loss": 2.1668,
      "step": 12
    },
    {
      "epoch": 0.0015960712093308778,
      "grad_norm": 0.21981309354305267,
      "learning_rate": 0.00013000000000000002,
      "loss": 2.0001,
      "step": 13
    },
    {
      "epoch": 0.0017188459177409454,
      "grad_norm": 0.2541789412498474,
      "learning_rate": 0.00014000000000000001,
      "loss": 2.2292,
      "step": 14
    },
    {
      "epoch": 0.001841620626151013,
      "grad_norm": 0.2910686433315277,
      "learning_rate": 0.00015,
      "loss": 2.2721,
      "step": 15
    },
    {
      "epoch": 0.0019643953345610805,
      "grad_norm": 0.29620736837387085,
      "learning_rate": 0.00016,
      "loss": 2.0413,
      "step": 16
    },
    {
      "epoch": 0.002087170042971148,
      "grad_norm": 0.26457780599594116,
      "learning_rate": 0.00017,
      "loss": 2.0395,
      "step": 17
    },
    {
      "epoch": 0.0022099447513812156,
      "grad_norm": 0.32531875371932983,
      "learning_rate": 0.00017999999999999998,
      "loss": 2.0072,
      "step": 18
    },
    {
      "epoch": 0.002332719459791283,
      "grad_norm": 0.30554890632629395,
      "learning_rate": 0.00019,
      "loss": 2.0086,
      "step": 19
    },
    {
      "epoch": 0.0024554941682013503,
      "grad_norm": 0.24684342741966248,
      "learning_rate": 0.0002,
      "loss": 1.8858,
      "step": 20
    },
    {
      "epoch": 0.002578268876611418,
      "grad_norm": 0.23107214272022247,
      "learning_rate": 0.00021,
      "loss": 2.0218,
      "step": 21
    },
    {
      "epoch": 0.0027010435850214854,
      "grad_norm": 0.2585574686527252,
      "learning_rate": 0.00022,
      "loss": 2.1243,
      "step": 22
    },
    {
      "epoch": 0.002823818293431553,
      "grad_norm": 0.21023592352867126,
      "learning_rate": 0.00023,
      "loss": 1.8638,
      "step": 23
    },
    {
      "epoch": 0.0029465930018416206,
      "grad_norm": 0.16762971878051758,
      "learning_rate": 0.00024,
      "loss": 1.9362,
      "step": 24
    },
    {
      "epoch": 0.003069367710251688,
      "grad_norm": 0.16743755340576172,
      "learning_rate": 0.00025,
      "loss": 1.9645,
      "step": 25
    },
    {
      "epoch": 0.0031921424186617557,
      "grad_norm": 0.20507946610450745,
      "learning_rate": 0.00026000000000000003,
      "loss": 1.9596,
      "step": 26
    },
    {
      "epoch": 0.0033149171270718232,
      "grad_norm": 0.19437649846076965,
      "learning_rate": 0.00027,
      "loss": 1.9492,
      "step": 27
    },
    {
      "epoch": 0.003437691835481891,
      "grad_norm": 0.2426401972770691,
      "learning_rate": 0.00028000000000000003,
      "loss": 1.9082,
      "step": 28
    },
    {
      "epoch": 0.0035604665438919584,
      "grad_norm": 0.21822507679462433,
      "learning_rate": 0.00029,
      "loss": 1.809,
      "step": 29
    },
    {
      "epoch": 0.003683241252302026,
      "grad_norm": 0.2195374220609665,
      "learning_rate": 0.0003,
      "loss": 1.8373,
      "step": 30
    },
    {
      "epoch": 0.0038060159607120935,
      "grad_norm": 0.22536775469779968,
      "learning_rate": 0.00031,
      "loss": 1.904,
      "step": 31
    },
    {
      "epoch": 0.003928790669122161,
      "grad_norm": 0.21460196375846863,
      "learning_rate": 0.00032,
      "loss": 1.8379,
      "step": 32
    },
    {
      "epoch": 0.004051565377532229,
      "grad_norm": 0.21507126092910767,
      "learning_rate": 0.00033,
      "loss": 1.9605,
      "step": 33
    },
    {
      "epoch": 0.004174340085942296,
      "grad_norm": 0.2226114273071289,
      "learning_rate": 0.00034,
      "loss": 1.8028,
      "step": 34
    },
    {
      "epoch": 0.004297114794352364,
      "grad_norm": 1.0964971780776978,
      "learning_rate": 0.00035,
      "loss": 1.835,
      "step": 35
    },
    {
      "epoch": 0.004419889502762431,
      "grad_norm": 0.18919435143470764,
      "learning_rate": 0.00035999999999999997,
      "loss": 1.8986,
      "step": 36
    },
    {
      "epoch": 0.004542664211172499,
      "grad_norm": 0.1421828269958496,
      "learning_rate": 0.00037,
      "loss": 1.8847,
      "step": 37
    },
    {
      "epoch": 0.004665438919582566,
      "grad_norm": 0.17190341651439667,
      "learning_rate": 0.00038,
      "loss": 1.7803,
      "step": 38
    },
    {
      "epoch": 0.004788213627992633,
      "grad_norm": 0.18993699550628662,
      "learning_rate": 0.00039000000000000005,
      "loss": 1.9311,
      "step": 39
    },
    {
      "epoch": 0.004910988336402701,
      "grad_norm": 0.15054425597190857,
      "learning_rate": 0.0004,
      "loss": 1.7949,
      "step": 40
    },
    {
      "epoch": 0.005033763044812768,
      "grad_norm": 0.16441649198532104,
      "learning_rate": 0.00041,
      "loss": 1.7697,
      "step": 41
    },
    {
      "epoch": 0.005156537753222836,
      "grad_norm": 0.1262015700340271,
      "learning_rate": 0.00042,
      "loss": 1.6702,
      "step": 42
    },
    {
      "epoch": 0.005279312461632903,
      "grad_norm": 0.1343669891357422,
      "learning_rate": 0.00043,
      "loss": 1.7133,
      "step": 43
    },
    {
      "epoch": 0.005402087170042971,
      "grad_norm": 0.16558490693569183,
      "learning_rate": 0.00044,
      "loss": 1.6971,
      "step": 44
    },
    {
      "epoch": 0.0055248618784530384,
      "grad_norm": 0.11018452793359756,
      "learning_rate": 0.00045000000000000004,
      "loss": 1.7602,
      "step": 45
    },
    {
      "epoch": 0.005647636586863106,
      "grad_norm": 0.1501052975654602,
      "learning_rate": 0.00046,
      "loss": 1.6303,
      "step": 46
    },
    {
      "epoch": 0.0057704112952731736,
      "grad_norm": 0.17312967777252197,
      "learning_rate": 0.00047,
      "loss": 1.7287,
      "step": 47
    },
    {
      "epoch": 0.005893186003683241,
      "grad_norm": 0.12311159074306488,
      "learning_rate": 0.00048,
      "loss": 1.7402,
      "step": 48
    },
    {
      "epoch": 0.006015960712093309,
      "grad_norm": 0.15959495306015015,
      "learning_rate": 0.00049,
      "loss": 1.7003,
      "step": 49
    },
    {
      "epoch": 0.006138735420503376,
      "grad_norm": 0.15426255762577057,
      "learning_rate": 0.0005,
      "loss": 1.8978,
      "step": 50
    },
    {
      "epoch": 0.006261510128913444,
      "grad_norm": 0.12657199800014496,
      "learning_rate": 0.00051,
      "loss": 1.787,
      "step": 51
    },
    {
      "epoch": 0.006384284837323511,
      "grad_norm": 0.14390455186367035,
      "learning_rate": 0.0005200000000000001,
      "loss": 1.8158,
      "step": 52
    },
    {
      "epoch": 0.006507059545733579,
      "grad_norm": 0.13885436952114105,
      "learning_rate": 0.0005300000000000001,
      "loss": 1.7314,
      "step": 53
    },
    {
      "epoch": 0.0066298342541436465,
      "grad_norm": 0.14917577803134918,
      "learning_rate": 0.00054,
      "loss": 1.8623,
      "step": 54
    },
    {
      "epoch": 0.006752608962553714,
      "grad_norm": 0.1332390457391739,
      "learning_rate": 0.00055,
      "loss": 1.76,
      "step": 55
    },
    {
      "epoch": 0.006875383670963782,
      "grad_norm": 0.2252107709646225,
      "learning_rate": 0.0005600000000000001,
      "loss": 1.6211,
      "step": 56
    },
    {
      "epoch": 0.006998158379373849,
      "grad_norm": 0.13706298172473907,
      "learning_rate": 0.00057,
      "loss": 1.7995,
      "step": 57
    },
    {
      "epoch": 0.007120933087783917,
      "grad_norm": 0.16202956438064575,
      "learning_rate": 0.00058,
      "loss": 1.6245,
      "step": 58
    },
    {
      "epoch": 0.007243707796193984,
      "grad_norm": 0.12908591330051422,
      "learning_rate": 0.00059,
      "loss": 1.8076,
      "step": 59
    },
    {
      "epoch": 0.007366482504604052,
      "grad_norm": 0.16744637489318848,
      "learning_rate": 0.0006,
      "loss": 1.7199,
      "step": 60
    },
    {
      "epoch": 0.007489257213014119,
      "grad_norm": 0.14621895551681519,
      "learning_rate": 0.00061,
      "loss": 1.7939,
      "step": 61
    },
    {
      "epoch": 0.007612031921424187,
      "grad_norm": 0.1531280279159546,
      "learning_rate": 0.00062,
      "loss": 1.6612,
      "step": 62
    },
    {
      "epoch": 0.0077348066298342545,
      "grad_norm": 0.12717439234256744,
      "learning_rate": 0.00063,
      "loss": 1.6512,
      "step": 63
    },
    {
      "epoch": 0.007857581338244322,
      "grad_norm": 0.1416880041360855,
      "learning_rate": 0.00064,
      "loss": 1.8052,
      "step": 64
    },
    {
      "epoch": 0.00798035604665439,
      "grad_norm": 0.13159920275211334,
      "learning_rate": 0.0006500000000000001,
      "loss": 1.6882,
      "step": 65
    },
    {
      "epoch": 0.008103130755064457,
      "grad_norm": 0.159307062625885,
      "learning_rate": 0.00066,
      "loss": 1.8829,
      "step": 66
    },
    {
      "epoch": 0.008225905463474525,
      "grad_norm": 0.17031125724315643,
      "learning_rate": 0.00067,
      "loss": 1.7596,
      "step": 67
    },
    {
      "epoch": 0.008348680171884592,
      "grad_norm": 0.1708480566740036,
      "learning_rate": 0.00068,
      "loss": 1.785,
      "step": 68
    },
    {
      "epoch": 0.00847145488029466,
      "grad_norm": 0.16865944862365723,
      "learning_rate": 0.00069,
      "loss": 1.6873,
      "step": 69
    },
    {
      "epoch": 0.008594229588704727,
      "grad_norm": 0.1494966596364975,
      "learning_rate": 0.0007,
      "loss": 1.691,
      "step": 70
    },
    {
      "epoch": 0.008717004297114795,
      "grad_norm": 0.13545110821723938,
      "learning_rate": 0.00071,
      "loss": 1.8135,
      "step": 71
    },
    {
      "epoch": 0.008839779005524863,
      "grad_norm": 0.13627250492572784,
      "learning_rate": 0.0007199999999999999,
      "loss": 1.8092,
      "step": 72
    },
    {
      "epoch": 0.00896255371393493,
      "grad_norm": 0.13512927293777466,
      "learning_rate": 0.00073,
      "loss": 1.7558,
      "step": 73
    },
    {
      "epoch": 0.009085328422344998,
      "grad_norm": 0.14082928001880646,
      "learning_rate": 0.00074,
      "loss": 1.8619,
      "step": 74
    },
    {
      "epoch": 0.009208103130755065,
      "grad_norm": 0.18883313238620758,
      "learning_rate": 0.00075,
      "loss": 1.7208,
      "step": 75
    },
    {
      "epoch": 0.009330877839165133,
      "grad_norm": 0.12510965764522552,
      "learning_rate": 0.00076,
      "loss": 1.6758,
      "step": 76
    },
    {
      "epoch": 0.0094536525475752,
      "grad_norm": 0.12287984043359756,
      "learning_rate": 0.0007700000000000001,
      "loss": 1.7079,
      "step": 77
    },
    {
      "epoch": 0.009576427255985266,
      "grad_norm": 0.14631223678588867,
      "learning_rate": 0.0007800000000000001,
      "loss": 1.7331,
      "step": 78
    },
    {
      "epoch": 0.009699201964395334,
      "grad_norm": 0.1913883090019226,
      "learning_rate": 0.00079,
      "loss": 1.8041,
      "step": 79
    },
    {
      "epoch": 0.009821976672805401,
      "grad_norm": 0.14207077026367188,
      "learning_rate": 0.0008,
      "loss": 1.7355,
      "step": 80
    },
    {
      "epoch": 0.009944751381215469,
      "grad_norm": 0.1470702439546585,
      "learning_rate": 0.0008100000000000001,
      "loss": 1.7523,
      "step": 81
    },
    {
      "epoch": 0.010067526089625536,
      "grad_norm": 0.15830354392528534,
      "learning_rate": 0.00082,
      "loss": 1.6011,
      "step": 82
    },
    {
      "epoch": 0.010190300798035604,
      "grad_norm": 0.16661451756954193,
      "learning_rate": 0.00083,
      "loss": 1.8963,
      "step": 83
    },
    {
      "epoch": 0.010313075506445672,
      "grad_norm": 0.13055278360843658,
      "learning_rate": 0.00084,
      "loss": 1.8137,
      "step": 84
    },
    {
      "epoch": 0.010435850214855739,
      "grad_norm": 0.121735118329525,
      "learning_rate": 0.00085,
      "loss": 1.7509,
      "step": 85
    },
    {
      "epoch": 0.010558624923265807,
      "grad_norm": 0.19595997035503387,
      "learning_rate": 0.00086,
      "loss": 1.7971,
      "step": 86
    },
    {
      "epoch": 0.010681399631675874,
      "grad_norm": 0.15679149329662323,
      "learning_rate": 0.00087,
      "loss": 1.7011,
      "step": 87
    },
    {
      "epoch": 0.010804174340085942,
      "grad_norm": 0.1885935217142105,
      "learning_rate": 0.00088,
      "loss": 1.7085,
      "step": 88
    },
    {
      "epoch": 0.01092694904849601,
      "grad_norm": 0.1889612227678299,
      "learning_rate": 0.0008900000000000001,
      "loss": 1.6613,
      "step": 89
    },
    {
      "epoch": 0.011049723756906077,
      "grad_norm": 0.14033889770507812,
      "learning_rate": 0.0009000000000000001,
      "loss": 1.7401,
      "step": 90
    },
    {
      "epoch": 0.011172498465316144,
      "grad_norm": 0.16272564232349396,
      "learning_rate": 0.00091,
      "loss": 1.7673,
      "step": 91
    },
    {
      "epoch": 0.011295273173726212,
      "grad_norm": 0.15043944120407104,
      "learning_rate": 0.00092,
      "loss": 1.7184,
      "step": 92
    },
    {
      "epoch": 0.01141804788213628,
      "grad_norm": 0.1602189987897873,
      "learning_rate": 0.00093,
      "loss": 1.6096,
      "step": 93
    },
    {
      "epoch": 0.011540822590546347,
      "grad_norm": 0.14198824763298035,
      "learning_rate": 0.00094,
      "loss": 1.7751,
      "step": 94
    },
    {
      "epoch": 0.011663597298956415,
      "grad_norm": 0.12274760752916336,
      "learning_rate": 0.00095,
      "loss": 1.6535,
      "step": 95
    },
    {
      "epoch": 0.011786372007366482,
      "grad_norm": 0.13458681106567383,
      "learning_rate": 0.00096,
      "loss": 1.866,
      "step": 96
    },
    {
      "epoch": 0.01190914671577655,
      "grad_norm": 0.16352485120296478,
      "learning_rate": 0.0009699999999999999,
      "loss": 1.7254,
      "step": 97
    },
    {
      "epoch": 0.012031921424186617,
      "grad_norm": 0.11433662474155426,
      "learning_rate": 0.00098,
      "loss": 1.7324,
      "step": 98
    },
    {
      "epoch": 0.012154696132596685,
      "grad_norm": 0.141954243183136,
      "learning_rate": 0.00099,
      "loss": 1.6652,
      "step": 99
    },
    {
      "epoch": 0.012277470841006752,
      "grad_norm": 0.12690599262714386,
      "learning_rate": 0.0,
      "loss": 1.7939,
      "step": 100
    }
  ],
  "logging_steps": 1,
  "max_steps": 100,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.01249925054464e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
